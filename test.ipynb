{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理库\n",
    "import numpy as np\n",
    "import torch\n",
    "# 模型代码\n",
    "from model import spsnet\n",
    "# 数据集代码\n",
    "from datasets import WHUBuilding\n",
    "from torch.utils.data import DataLoader\n",
    "# 信息输出代码\n",
    "from tqdm import tqdm\n",
    "# 图片处理代码\n",
    "from PIL import Image\n",
    "import imgviz\n",
    "# 其他\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = spsnet.__dict__[\"SPSNet\"](in_channel=3, out_channel=1, spc=3).cuda()\n",
    "# 加载预训练参数\n",
    "checkpoint = torch.load(r'checkpoints/sps-unet-whu/best_model.pt')\n",
    "model.load_state_dict(checkpoint[\"state_dict\"], strict=False)\n",
    "del checkpoint\n",
    "\n",
    "# 加载数据集\n",
    "dataset_val = WHUBuilding(root=Path('/mnt/d/dataset/WHU/'), mode=\"test\")\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=2, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_colored_mask(mask, save_path):\n",
    "    mask = Image.fromarray(mask.astype(np.uint8), mode=\"P\")\n",
    "    colormap = imgviz.label_colormap()\n",
    "    mask.putpalette(colormap.flatten())\n",
    "    mask.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3848/3848 [01:50<00:00, 34.93it/s]\n"
     ]
    }
   ],
   "source": [
    "ori_dir = Path('/mnt/d/dataset/WHU/test/ori_label')\n",
    "label_list = list(ori_dir.glob('*.tif'))\n",
    "\n",
    "target_dir = Path('/mnt/d/dataset/WHU/test/label')\n",
    "for lab in tqdm(label_list):\n",
    "    data = np.array(Image.open(lab))\n",
    "    new_data = data.copy()\n",
    "    new_data[new_data == 255] = 1\n",
    "    save_colored_mask(new_data, target_dir.joinpath(lab.stem + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(64, 9, kernel_size=(3, 3), padding=1, bias=True),\n",
    "            nn.Softmax(dim=1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU6(inplace=True)\n",
       "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU6(inplace=True)\n",
       "  (6): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU6'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "Flops:  1.6312G\n",
      "params参数量:  0.0247M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "\n",
    "input = torch.randn(1, 3, 256, 256) \n",
    "Flops, params = profile(net, inputs=(input,)) # macs\n",
    "print('Flops: % .4fG'%(Flops / 1000000000)) # 计算量\n",
    "print('params参数量: % .4fM'% (params / 1000000))   #参数量：等价与上面的summary输出的Total params值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(4, 9, 256, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.softmax(dim=1).argmax(dim=1)\n",
    "t = t.permute(1, 2, 0)\n",
    "t = F.one_hot(t, 9)\n",
    "t = t.permute(2, 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(1, 3, 4, 4)\n",
    "mask = torch.randint(0, 3, (1, 4, 4))\n",
    "\n",
    "func = torch.nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = func(t, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list = list(Path('/home/eveleaf/MyDataset/yqdataset/deepglobe/train/mask').glob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22325/22325 [01:21<00:00, 274.90it/s]\n"
     ]
    }
   ],
   "source": [
    "lab = 0\n",
    "for mask in tqdm(mask_list):\n",
    "    lab = max(np.array(Image.open(mask)).max(), lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
